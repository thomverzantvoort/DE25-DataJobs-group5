```mermaid
flowchart LR
    %% Node styles
    classDef ingestion fill:#ffe9c6,stroke:#e09800,stroke-width:1px,color:#402400;
    classDef messaging fill:#ffd4d4,stroke:#c0392b,stroke-width:1px,color:#5a0c0c;
    classDef compute fill:#d6eeff,stroke:#0b6fa4,stroke-width:1px,color:#042f47;
    classDef storage fill:#e7ffe9,stroke:#1c8c32,stroke-width:1px,color:#0f3f18;
    classDef viz fill:#efe2ff,stroke:#7a42c3,stroke-width:1px,color:#2a104f;

    %% 1. Data Landing
    subgraph Landing["Data Landing & Trigger"]
        DS["Netflix 2025 Dataset\n(users, movies, watch_history,\nreviews, search_logs, recommendation_logs)"]:::ingestion
        GCS["Google Cloud Storage\nBucket: data_netflix_2025\n/raw/*.csv   /streaming/*.json"]:::storage
        DS -->|Raw CSV upload| GCS
    end

    %% 2. Streaming Motion
    subgraph Streaming["Speed Layer – Real-Time Motion"]
        Producer["Local kafka_producer.py\n5 events/sec\nExternal IP 136.113.194.230:9092"]:::messaging
        Kafka["Kafka Broker (kafka1)\nTopic netflix_watch_events\n3 partitions"]:::messaging
        SparkStream["Spark Structured Streaming\nNotebook 03_streaming_pipeline_...\nMaster 7077 / UI 8080\nWorkers x2 (2 GB)"]:::compute
        Producer -->|JSON events| Kafka -->|readStream| SparkStream
        SparkStream -->|Join static lookup (users, movies)| SparkStream
        SparkStream -->|5-min windows, 10s trigger,\n10m watermark, churn detection| BQSpeed["BigQuery netflix_streaming.engagement_health_realtime"]:::storage
    end

    %% 3. Batch Motion
    subgraph Batch["Batch Layer – Historical Motion"]
        SparkBatch["Spark Batch Pipeline\nBatch_pipeline_Netflix.ipynb\nShared master + 2 workers"]:::compute
        SparkBatch -->|Load CSV from GCS| Clean["Data quality + cleaning\nCritical columns enforced"]:::compute
        Clean --> Join["Star schema join\nwatch_history + users + movies + reviews"]:::compute
        Join --> Agg["Monthly aggregations\nmonthly_engagement, cohort_retention,\ncontent/genre performance, monthly_active_users"]:::compute
        Agg --> BQBatch["BigQuery netflix_processed\nClean tables + aggregates"]:::storage
    end

    %% 4. Unified Serving & Motion to Visualization
    subgraph Serving["Unified Serving & Visualization"]
        BigQuery["Google BigQuery\n(speed + batch datasets)"]:::storage
        Looker["Looker Studio Dashboards\n• Real-Time Engagement\n• Historical Trends"]:::viz
        BQSpeed --> BigQuery
        BQBatch --> BigQuery
        BigQuery -->|Live dashboards| Looker
    end

    %% Motion cues (conceptual arrows)
    GCS -.->|/streaming/*.json feed| Streaming
    GCS -.->|/raw/*.csv feed| Batch
    class DS ingestion
```


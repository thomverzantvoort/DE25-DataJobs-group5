{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_pipeline_netflix.ipynb\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, when\n",
    "\n",
    "# 1. Start Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"NetflixBatchPipeline\")\n",
    "        .master(\"spark://spark-master:7077\")\n",
    "        .config(\"spark.driver.memory\", \"2g\")\n",
    "        .config(\"spark.executor.memory\", \"2g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# 2. Read data from GCS or local volume (adjust path)\n",
    "# netflix_path = \"gs://de25-group5-raw/netflix/\"\n",
    "netflix_path = \"/home/jovyan/work/data/\" # path to google bucket\n",
    "\n",
    "users_df = spark.read.option(\"header\", True).csv(f\"{netflix_path}users.csv\")\n",
    "movies_df = spark.read.option(\"header\", True).csv(f\"{netflix_path}movies.csv\")\n",
    "watch_df = spark.read.option(\"header\", True).csv(f\"{netflix_path}watch_history.csv\")\n",
    "\n",
    "print(\"Loaded datasets:\")\n",
    "print(f\"Users: {users_df.count()}  Movies: {movies_df.count()}  Watch: {watch_df.count()}\")\n",
    "\n",
    "# 3. Quick cleaning and join\n",
    "# Example: join watch_history with users and movies\n",
    "joined_df = (\n",
    "    watch_df.join(users_df, \"user_id\", \"left\")\n",
    "             .join(movies_df, \"movie_id\", \"left\")\n",
    ")\n",
    "\n",
    "# 4. Simple aggregation example\n",
    "agg_df = (\n",
    "    joined_df.groupBy(\"country\", \"subscription_plan\")\n",
    "             .agg(\n",
    "                 count(\"*\").alias(\"total_sessions\"),\n",
    "                 avg(col(\"progress_percentage\")).alias(\"avg_progress\")\n",
    "             )\n",
    ")\n",
    "\n",
    "agg_df.show(10, truncate=False)\n",
    "\n",
    "# 5. Write result to BigQuery\n",
    "# (youâ€™ll adjust project and dataset names)\n",
    "agg_df.write.format(\"bigquery\") \\\n",
    "    .option(\"table\", \"de25_group5.batch_country_progress\") \\\n",
    "    .option(\"temporaryGcsBucket\", \"de25-group5-temp\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-data-architecture-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

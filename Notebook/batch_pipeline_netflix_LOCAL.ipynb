{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Spark session (no GCS, no BigQuery)\n",
    "# -------------------------------------------------------------------\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"NetflixBatchPipelineLocal\")\n",
    "        .master(\"spark://spark-master:7077\")\n",
    "        .config(\"spark.driver.memory\", \"2g\")\n",
    "        .config(\"spark.executor.memory\", \"2g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Read Netflix data from local Docker-mounted /data folder\n",
    "# -------------------------------------------------------------------\n",
    "# Inside the Jupyter container, /home/jovyan/work/data/ maps to your host ~/data\n",
    "netflix_path = \"/home/jovyan/data/\"\n",
    "\n",
    "users_df  = spark.read.option(\"header\", True).csv(f\"{netflix_path}users.csv\")\n",
    "movies_df = spark.read.option(\"header\", True).csv(f\"{netflix_path}movies.csv\")\n",
    "watch_df  = spark.read.option(\"header\", True).csv(f\"{netflix_path}watch_history.csv\")\n",
    "\n",
    "print(f\"Users: {users_df.count()}  Movies: {movies_df.count()}  Watch: {watch_df.count()}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Example transformation: join and aggregate\n",
    "# -------------------------------------------------------------------\n",
    "joined_df = (\n",
    "    watch_df.join(users_df, \"user_id\", \"left\")\n",
    "             .join(movies_df, \"movie_id\", \"left\")\n",
    ")\n",
    "\n",
    "agg_df = (\n",
    "    joined_df.groupBy(\"country\", \"subscription_plan\")\n",
    "             .agg(\n",
    "                 count(\"*\").alias(\"total_sessions\"),\n",
    "                 avg(col(\"progress_percentage\")).alias(\"avg_progress\")\n",
    "             )\n",
    ")\n",
    "\n",
    "agg_df.show(10, truncate=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Optional: write results locally to CSV (for debugging)\n",
    "# -------------------------------------------------------------------\n",
    "output_path = \"/home/jovyan/data/output_netflix_summary\"\n",
    "agg_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(output_path)\n",
    "\n",
    "print(f\"âœ… Results written to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-data-architecture-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
